{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for MUR SST on AWS  \n",
    "\n",
    "- Funding: Interagency Implementation and Advanced Concepts Team [IMPACT](https://earthdata.nasa.gov/esds/impact) for the Earth Science Data Systems (ESDS) program and AWS Public Dataset Program\n",
    "\n",
    "Credits: Tutorial development\n",
    "* [Dr. Chelle Gentemann](mailto:gentemann@faralloninstitute.org) -  [Twitter](https://twitter.com/ChelleGentemann)   - Farallon Institute\n",
    "* [Dr. Rich Signell](mailto:rsignell@usgs.gov) - [Twitter](https://twitter.com/rsignell) - USGS\n",
    "* [Dr. Ryan Abernathey](mailto:rpa@ldeo.columbia.edu) - [Twitter](https://twitter.com/rabernat) - LDEO\n",
    "\n",
    "\n",
    "Credits: Creating of the Zarr MUR SST dataset.  \n",
    "\n",
    "* [Aimee Barciauskas](mailto:aimee@developmentseed.org) - [Twitter](https://twitter.com/_aimeeb) - Development Seed\n",
    "* [Dr. Rich Signell](mailto:rsignell@usgs.gov) - [Twitter](https://twitter.com/rsignell) - USGS\n",
    "* [Dr. Chelle Gentemann](mailto:gentemann@faralloninstitute.org)  -  [Twitter](https://twitter.com/ChelleGentemann) - Farallon Institute\n",
    "* [Joseph Flasher](mailto:jflasher@amazon.com) [Twitter](https://twitter.com/joseph_flasher) - AWS\n",
    "\n",
    "Credits: Tutorial review and comments.\n",
    "* [Dr. Ed Armstrong](mailto:edward.m.armstrong@jpl.nasa.gov) - JPL PODAAC\n",
    "\n",
    "-------------\n",
    "\n",
    "## Please note that this is global, 1 km, daily data.  This is a very large dataset and the analyses below can take up to 5-10 minutes\n",
    "\n",
    "## [MUR SST](https://podaac.jpl.nasa.gov/Multi-scale_Ultra-high_Resolution_MUR-SST) [AWS Public dataset program](https://registry.opendata.aws/mur/) \n",
    "\n",
    "### This Pangeo binder is faster when run on AWS.  \n",
    "\n",
    "![image](https://podaac.jpl.nasa.gov/Podaac/thumbnails/MUR-JPL-L4-GLOB-v4.1.jpg)\n",
    "\n",
    "This code shows how to read from a s3 bucket.  \n",
    "Right now (2/16/2020) this takes ~1min on AWS and ~2 min on google cloud, there are couple issues here and we are working to solve both.  \n",
    "1. Some shortcomings in the s3fs and zarr formats have been identified.  To work on these, git issues were raised to the developers [here](https://github.com/dask/s3fs/issues/285) and [here](https://github.com/zarr-developers/zarr-python/issues/536)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To run this notebook\n",
    "\n",
    "Code is in the cells that have <span style=\"color: blue;\">In [  ]:</span> to the left of the cell and have a colored background\n",
    "\n",
    "To run the code:\n",
    "- option 1) click anywhere in the cell, then hold shift and press Enter\n",
    "- option 2) click on the Run button at the top of the page in the dashboard\n",
    "\n",
    "# Structure of this tutorial\n",
    "\n",
    "1. Opening data\n",
    "2. Data exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Opening data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "## Import python packages\n",
    "\n",
    "It is nice to turn off warnings and set xarray display options.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import fsspec\n",
    "\n",
    "warnings.simplefilter('ignore') # filter some warning messages\n",
    "xr.set_options(display_style=\"html\")  #display dataset nicely "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a cluster, a group of computers that will work together.\n",
    "\n",
    "(A cluster is the key to big data analysis on on Cloud.)\n",
    "\n",
    "- This will set up a [dask kubernetes](https://docs.dask.org/en/latest/setup/kubernetes.html) cluster for your analysis and give you a path that you can paste into the top of the Dask dashboard to visualize parts of your cluster.  \n",
    "- You don't need to paste the link below into the Dask dashboard for this to work, but it will help you visualize progress.\n",
    "- Try 20 workers to start (during the tutorial) but you can increase to speed things up later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_gateway import Gateway\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gateway = Gateway()\n",
    "cluster = gateway.new_cluster()\n",
    "cluster.adapt(minimum=1, maximum=20)\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "attachments": {
    "images.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAACIAAAAkCAIAAABjfH+IAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAQxSURBVEhL7ZdtTBtlHMDvee56faUtbeFoeRsKzBDU6VCck2nQDNBsEWOGMUbch7ktMdGZGF2cMfrBmPgBXyIJ+kW3uDlM1DAy5mamlWBkMuIwtHsBynvpC22hvV6v17vzGXeaFK6wMvbF7Peh9/z/z//y6/95nty1QBRF7NYD5est5rZmJQKXkEcZ2BhN0ueh3b1yoMTGaLjQ9MIfnXKgxMZo2Gm3kKTZGZccr+BmNQITSS36mYlLAGCMp1/OruCmNGIynpwdYjyXRC6pshYlZ/9GOXkunfVrRC4RHTwJdZbYcC9ZcKexpllMJbjAmDydzjo1qcVA6FwbhoEUwyemLxuq60mqHIM4H/PJFelkrRFYOtJ3PPDj+zwd0m7e6e/6TFu2RW3LxyCEpFZgY3JdOllo2DlP+Pfvvcffif51RmUrtTa9GfzpqMAy5oeeRpsPSR1UqcWksoaQrxmIDl+gR4f5WIj1XuUX53CDQV9WZW44QOQW+ru/iF0dpHbvZ6cuQgKgBUQNoQ9F1ugmMuAMnD1BXxlQmfNtDXuL97VRz75NmOzekx9H+s9YH9ujKSiNj14g7dUYeqEIPIC4fGc6a3Qj8pyaKqo43AEIlZSJDg9MH/tIYKP25gOWHc1h5zFI4CR1F9oVkYsDdY5Utow1uuHpKKEzSA76msvzybsjH7yGAbz4pcPIwYV9MZdTW74dkLpUZAZ9K1XuJunGZayhScyMkVTJ0lAc/fCtSL/T0bK/8kiH8d46URD8pz7HtTmGuxvRNNIAgoB621LxclbTcAvzyXmvtqRyKQKWRxsAhHlNLbg+B+2Ev6uDnR0xPvgM1FxfqMTEn4RlE9QYl4qXs5oGbQN6UmmLy6VQX1nFs3FmchSN/We/nXf+YKxpMFTVoTA5dxl1o7bfs1SowGqa0G9dZF7hv91gpvsfBpjITFyZ6/rK29lurm2y1r8gTdHu81BtIIu2SOFKMmpi7ov0mDt3WyPA5dMISTXU6dm5SW7el7ezxb7nVen4MuOD7NSQvvpJmOGYITJoRDH46ymI45ZHnpISXMSfioYIvZ5naGp3q6PlFbRPKM/HFyK9R0mqQlOyVapURFkT6jsd6T9neqCe9U0Gz3dOtB+a6jiE3sSoMwAAaS2QyoQEHehuw8SUaXsrOtNSUhEFDTM1Mv1NGwZAuO/0+KdvBH8+gY6ZuXaXunCzkGKhRiuVXXf0tKfCXnPdXtygfI7/Q+EpwEWC+Y3PIw2hN2ocpWSeg7Q5UJ6Px3g6prJQaJyYHQv2dPDxgPXxVm3ZasslkcWPW3rEde29l0sPHkkGxqNDv5A2yvbEi7qKGnl6VbLQeL/70tf9NWmzAlww1+zI33UQ1xrkubXIQuN6/Tlu0W+6r7ageZ/GcYecvTFuVJOioyFnj2nrNjVVLKey4fYfj3Xwf9Jg2D83JLQOnbSPhQAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ☝️ Don’t forget to click the link above or copy it to the Dask dashboard ![images.png](attachment:images.png) on the left to view the scheduler dashboard! **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Dataset\n",
    "\n",
    "Here we load the dataset from the zarr store. Note that this very large dataset initializes nearly instantly, and we can see the full list of variables and coordinates.\n",
    "\n",
    "### Examine Metadata\n",
    "\n",
    "For those unfamiliar with this dataset, the variable metadata is very helpful for understanding what the variables actually represent\n",
    "Printing the dataset will show you the dimensions, coordinates, and data variables with clickable icons at the end that show more metadata and size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "file_location = 's3://mur-sst/zarr-v1'\n",
    "\n",
    "ds_sst = xr.open_zarr(fsspec.get_mapper(file_location, anon=True),consolidated=True)\n",
    "\n",
    "ds_sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.  Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's explore the data\n",
    "\n",
    "- With all data, it is important to explore it and understand what is contains before doing an analysis.\n",
    "- The ice mask used by MUR SST is from NSIDC and is based on satellite passive microwave estimates of sea ice concentration\n",
    "- The satellite data isn't available near land, so the is no estimate of sea ice concentration near land\n",
    "- For this data, it means that there are some erroneous SSTs near land, that is likely ice and this is something to be aware of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sst = ds_sst['analysed_sst']\n",
    "\n",
    "cond = (ds_sst.mask==1) & ((ds_sst.sea_ice_fraction<.15) | np.isnan(ds_sst.sea_ice_fraction))\n",
    "\n",
    "sst_masked = ds_sst['analysed_sst'].where(cond)\n",
    "\n",
    "sst_masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ``.groupby`` and ``.resample``\n",
    "#### Create a monthly SST anomaly dataset\n",
    "- First create a monthly version of the dataset using ``.resample``.  Two nice arguments for ``.resample``: ``keep_addrs`` which keeps the metadata and ``skipna`` which ensures that only data that is always present is included\n",
    "- Calculate the monthly climatology using ``.groupby``\n",
    "- Calculate the anomaly \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#create a daily climatology and anomaly\n",
    "climatology_mean = sst_masked.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)\n",
    "\n",
    "sst_anomaly = sst_masked.groupby('time.dayofyear')-climatology_mean  #take out annual mean to remove trends\n",
    "\n",
    "#create a monthly dataset, climatology, and anomaly\n",
    "sst_monthly = sst_masked.resample(time='1MS').mean('time',keep_attrs=True,skipna=False)\n",
    "\n",
    "climatology_mean_monthly = sst_monthly.groupby('time.month').mean('time',keep_attrs=True,skipna=False)\n",
    "\n",
    "sst_anomaly_monthly = sst_monthly.groupby('time.month')-climatology_mean_monthly  #take out annual mean to remove trends\n",
    "\n",
    "sst_anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``xarray`` plotting functions rely on matplotlib internally, but they make use of all available metadata to make the plotting operations more intuitive and interpretable. More plotting examples are given [here](http://xarray.pydata.org/en/stable/plotting.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we use ``holoviews`` and ``hvplot`` for interactive graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "from holoviews.operation.datashader import regrid\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the SST anomaly timeseries in the Pacific Blob Region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "daily = sst_anomaly.sel(lon=-140, lat=53).drop('dayofyear').load()\n",
    "\n",
    "monthly = sst_anomaly_monthly.sel(lon=-140, lat=53).drop('month').load()\n",
    "\n",
    "daily.hvplot(grid=True) * monthly.hvplot(grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting on maps\n",
    "\n",
    "For plotting on maps, we rely on the excellent [cartopy](http://scitools.org.uk/cartopy/docs/latest/index.html) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a global image of SST on 9/1/2016\n",
    "\n",
    "### In cartopy you need to define the map projection you want to plot.  \n",
    "\n",
    "- Common ones are Ortographic and PlateCarree.\n",
    "- You can add coastlines and gridlines to the axes as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sst_sept = sst_monthly.sel(time='2016-09-01').load()\n",
    "\n",
    "(sst_sept-273.15).hvplot.quadmesh(x='lon', y='lat', geo=True, \n",
    "                         rasterize=True, clim=(0,32), \n",
    "                         cmap='turbo', \n",
    "                         projection=ccrs.Orthographic(-130, 35),\n",
    "                         coastline='110m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please close cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A nice cartopy tutorial is [here](http://earthpy.org/tag/visualization.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xarray can do more!\n",
    "\n",
    "* concatentaion\n",
    "* open network located files with openDAP\n",
    "* import and export Pandas DataFrames\n",
    "* .nc dump to \n",
    "* groupby_bins\n",
    "* resampling and reduction\n",
    "\n",
    "For more details, read this blog post: http://continuum.io/blog/xray-dask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where can I find more info?\n",
    "\n",
    "### For more information about xarray\n",
    "\n",
    "- Read the [online documentation](http://xarray.pydata.org/)\n",
    "- Ask questions on [StackOverflow](http://stackoverflow.com/questions/tagged/python-xarray)\n",
    "- View the source code and file bug reports on [GitHub](http://github.com/pydata/xarray/)\n",
    "\n",
    "### For more doing data analysis with Python:\n",
    "\n",
    "- Thomas Wiecki, [A modern guide to getting started with Data Science and Python](http://twiecki.github.io/blog/2014/11/18/python-for-data-science/)\n",
    "- Wes McKinney, [Python for Data Analysis](http://shop.oreilly.com/product/0636920023784.do) (book)\n",
    "\n",
    "### Packages building on xarray for the geophysical sciences\n",
    "\n",
    "\n",
    "- [eofs](https://github.com/ajdawson/eofs): empirical orthogonal functions by Andrew Dawson\n",
    "- [infinite-diff](https://github.com/spencerahill/infinite-diff) by Spencer Hill \n",
    "- [aospy](https://github.com/spencerahill/aospy) by Spencer Hill and Spencer Clark\n",
    "- [regionmask](https://github.com/mathause/regionmask) by Mathias Hauser\n",
    "- [salem](https://github.com/fmaussion/salem) by Fabien Maussion\n",
    "\n",
    "Resources for teaching and learning xarray in geosciences:\n",
    "- [Fabien's teaching repo](https://github.com/fmaussion/teaching): courses that combine teaching climatology and xarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
