{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for MUR SST on AWS  \n",
    "\n",
    "- Funding: Interagency Implementation and Advanced Concepts Team [IMPACT](https://earthdata.nasa.gov/esds/impact) for the Earth Science Data Systems (ESDS) program and AWS Public Dataset Program\n",
    "\n",
    "Credits: Tutorial development\n",
    "* [Dr. Chelle Gentemann](mailto:gentemann@faralloninstitute.org)    - Farallon Institute, USA\n",
    "* [Dr. Rich Signell](mailto:rsignell@usgs.gov) - USGS\n",
    "* [Dr. Ryan Abernathey](mailto:rpa@ldeo.columbia.edu))\n",
    "\n",
    "\n",
    "Credits: Creating of the Zarr MUR SST dataset\n",
    "* [Aimee Barciauskas](mailto:aimee@developmentseed.org) - Development Seed\n",
    "* [Dr. Rich Signell](mailto:rsignell@usgs.gov) - USGS\n",
    "* [Dr. Chelle Gentemann](mailto:gentemann@faralloninstitute.org)    - Farallon Institute, USA\n",
    "* [Joseph Flasher](mailto:jflasher@amazon.com) - AWS\n",
    "-------------\n",
    "\n",
    "## Please note that this is global, 1 km, daily data.  This is a very large dataset and the analyses below can take up to 5-10 minutes\n",
    "\n",
    "## [MUR SST](https://podaac.jpl.nasa.gov/Multi-scale_Ultra-high_Resolution_MUR-SST) [AWS Public dataset program](https://registry.opendata.aws/mur/) \n",
    "\n",
    "### Access the MUR SST which is in an s3 bucket.  \n",
    "### This Pangeo binder is faster when run on AWS.  \n",
    "\n",
    "![image](https://podaac.jpl.nasa.gov/Podaac/thumbnails/MUR-JPL-L4-GLOB-v4.1.jpg)\n",
    "\n",
    "This code is an example of how to read from a s3 bucket.  \n",
    "\n",
    "Right now (2/16/2020) this takes ~1min on AWS and ~2 min on google cloud, there are two issues here and we are working to solve both.  \n",
    "1. In our Zarr datastore the time coodinate is chunked.  We should have this fixed by 3/1/2020.\n",
    "1. Some shortcomings in the s3fs and zarr formats have been identified.  To work on these, git issues were raised to the developers [here](https://github.com/dask/s3fs/issues/285) and [here](https://github.com/zarr-developers/zarr-python/issues/536)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure of this tutorial\n",
    "\n",
    "1. Opening data\n",
    "2. Data exploration\n",
    "2. Data plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Opening data\n",
    "-------------------\n",
    "\n",
    "## Import python packages\n",
    "\n",
    "It is nice to turn off warnings and set xarray display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import fsspec\n",
    "\n",
    "warnings.simplefilter('ignore') # filter some warning messages\n",
    "xr.set_options(display_style=\"html\")  #display dataset nicely "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a cluster, a group of computers that will work together.\n",
    "\n",
    "(A cluster is the key to big data analysis on on Cloud.)\n",
    "\n",
    "- This will set up a [dask kubernetes](https://docs.dask.org/en/latest/setup/kubernetes.html) cluster for your analysis and give you a path that you can paste into the top of the Dask dashboard to visualize parts of your cluster.  \n",
    "- You don't need to paste the link below into the Dask dashboard for this to work, but it will help you visualize progress.\n",
    "- Try 40 workers to start (during the tutorial) but you can increase to speed things up later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_kubernetes import KubeCluster\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = KubeCluster()\n",
    "cluster.adapt(minimum=1, maximum=20, interval='2s', wait_count=3)\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "attachments": {
    "images.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAACIAAAAkCAIAAABjfH+IAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAQxSURBVEhL7ZdtTBtlHMDvee56faUtbeFoeRsKzBDU6VCck2nQDNBsEWOGMUbch7ktMdGZGF2cMfrBmPgBXyIJ+kW3uDlM1DAy5mamlWBkMuIwtHsBynvpC22hvV6v17vzGXeaFK6wMvbF7Peh9/z/z//y6/95nty1QBRF7NYD5est5rZmJQKXkEcZ2BhN0ueh3b1yoMTGaLjQ9MIfnXKgxMZo2Gm3kKTZGZccr+BmNQITSS36mYlLAGCMp1/OruCmNGIynpwdYjyXRC6pshYlZ/9GOXkunfVrRC4RHTwJdZbYcC9ZcKexpllMJbjAmDydzjo1qcVA6FwbhoEUwyemLxuq60mqHIM4H/PJFelkrRFYOtJ3PPDj+zwd0m7e6e/6TFu2RW3LxyCEpFZgY3JdOllo2DlP+Pfvvcffif51RmUrtTa9GfzpqMAy5oeeRpsPSR1UqcWksoaQrxmIDl+gR4f5WIj1XuUX53CDQV9WZW44QOQW+ru/iF0dpHbvZ6cuQgKgBUQNoQ9F1ugmMuAMnD1BXxlQmfNtDXuL97VRz75NmOzekx9H+s9YH9ujKSiNj14g7dUYeqEIPIC4fGc6a3Qj8pyaKqo43AEIlZSJDg9MH/tIYKP25gOWHc1h5zFI4CR1F9oVkYsDdY5Utow1uuHpKKEzSA76msvzybsjH7yGAbz4pcPIwYV9MZdTW74dkLpUZAZ9K1XuJunGZayhScyMkVTJ0lAc/fCtSL/T0bK/8kiH8d46URD8pz7HtTmGuxvRNNIAgoB621LxclbTcAvzyXmvtqRyKQKWRxsAhHlNLbg+B+2Ev6uDnR0xPvgM1FxfqMTEn4RlE9QYl4qXs5oGbQN6UmmLy6VQX1nFs3FmchSN/We/nXf+YKxpMFTVoTA5dxl1o7bfs1SowGqa0G9dZF7hv91gpvsfBpjITFyZ6/rK29lurm2y1r8gTdHu81BtIIu2SOFKMmpi7ov0mDt3WyPA5dMISTXU6dm5SW7el7ezxb7nVen4MuOD7NSQvvpJmOGYITJoRDH46ymI45ZHnpISXMSfioYIvZ5naGp3q6PlFbRPKM/HFyK9R0mqQlOyVapURFkT6jsd6T9neqCe9U0Gz3dOtB+a6jiE3sSoMwAAaS2QyoQEHehuw8SUaXsrOtNSUhEFDTM1Mv1NGwZAuO/0+KdvBH8+gY6ZuXaXunCzkGKhRiuVXXf0tKfCXnPdXtygfI7/Q+EpwEWC+Y3PIw2hN2ocpWSeg7Q5UJ6Px3g6prJQaJyYHQv2dPDxgPXxVm3ZasslkcWPW3rEde29l0sPHkkGxqNDv5A2yvbEi7qKGnl6VbLQeL/70tf9NWmzAlww1+zI33UQ1xrkubXIQuN6/Tlu0W+6r7ageZ/GcYecvTFuVJOioyFnj2nrNjVVLKey4fYfj3Xwf9Jg2D83JLQOnbSPhQAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ☝️ Don’t forget to click the link above or copy it to the Dask dashboard ![images.png](attachment:images.png) on the left to view the scheduler dashboard! **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Dataset\n",
    "\n",
    "Here we load the dataset from the zarr store. Note that this very large dataset initializes nearly instantly, and we can see the full list of variables and coordinates.\n",
    "\n",
    "### Examine Metadata\n",
    "\n",
    "For those unfamiliar with this dataset, the variable metadata is very helpful for understanding what the variables actually represent\n",
    "Printing the dataset will show you the dimensions, coordinates, and data variables with clickable icons at the end that show more metadata and size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "file_location = 's3://mur-sst/zarr'\n",
    "\n",
    "ds_sst = xr.open_zarr(fsspec.get_mapper(file_location, anon=True),consolidated=True)\n",
    "\n",
    "ds_sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.  Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's explore the data\n",
    "\n",
    "- look at all the SST data\n",
    "- look at the SST data masked to only ocean and ice-free data\n",
    "\n",
    "- With all data, it is important to explore it and understand what is contains before doing an analysis.\n",
    "- The ice mask used by MUR SST is from NSIDC and is based on satellite passive microwave estimates of sea ice concentration\n",
    "- The satellite data isn't available near land, so the is no estimate of sea ice concentration near land\n",
    "- For this data, it means that there are some erroneous SSTs near land, that is likely ice and this is something to be aware of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst = ds_sst['analysed_sst']\n",
    "\n",
    "cond = (ds_sst.mask==1) & ((ds_sst.sea_ice_fraction<.15) | np.isnan(ds_sst.sea_ice_fraction))\n",
    "\n",
    "sst_masked = ds_sst['analysed_sst'].where(cond)\n",
    "\n",
    "sst_masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ``.groupby`` and ``.resample``\n",
    "\n",
    "Xarray has a lot of nice build-in methods, such as [.resampe](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.resample.html#xarray-dataset-resample) which can upsample or downsample data and [.mean](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.mean.html#xarray-dataarray-mean). Here we use these to calculate a climatology and anomoaly.\n",
    "\n",
    "#### Create a daily SST anomaly dataset\n",
    "- Calculate the daily climatology using ``.groupby``\n",
    "- Calculate the anomaly \n",
    "\n",
    "#### Create a monthly SST anomaly dataset\n",
    "- First create a monthly version of the dataset using ``.resample``.  Two nice arguments for ``.resample``: ``keep_addrs`` which keeps the metadata and ``skipna`` which ensures that only data that is always present is included\n",
    "- Calculate the monthly climatology using ``.groupby``\n",
    "- Calculate the anomaly \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#create a daily climatology and anomaly\n",
    "climatology_mean = sst_masked.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)\n",
    "\n",
    "sst_anomaly = sst_masked.groupby('time.dayofyear')-climatology_mean  #take out annual mean to remove trends\n",
    "\n",
    "#create a monthly dataset, climatology, and anomaly\n",
    "sst_monthly = sst_masked.resample(time='1MS').mean('time',keep_attrs=True,skipna=False)\n",
    "\n",
    "climatology_mean_monthly = sst_monthly.groupby('time.month').mean('time',keep_attrs=True,skipna=False)\n",
    "\n",
    "sst_anomaly_monthly = sst_monthly.groupby('time.month')-climatology_mean_monthly  #take out annual mean to remove trends\n",
    "\n",
    "sst_anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``xarray`` plotting functions rely on matplotlib internally, but they make use of all available metadata to make the plotting operations more intuitive and interpretable. More plotting examples are given [here](http://xarray.pydata.org/en/stable/plotting.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we use ``holoviews`` and ``hvplot`` for interactive graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "from holoviews.operation.datashader import regrid\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the SST timeseries in the Pacific Blob Region\n",
    "Plot both the daily and monthly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = sst.sel(lon=-140, lat=53).load()\n",
    "\n",
    "monthly = sst_monthly.sel(lon=-140, lat=53).load()\n",
    "\n",
    "daily.hvplot(grid=True) * monthly.hvplot(grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the SST anomaly timeseries in the Pacific Blob Region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = sst_anomaly.sel(lon=-140, lat=53).drop('dayofyear').load()\n",
    "\n",
    "monthly = sst_anomaly_monthly.sel(lon=-140, lat=53).drop('month').load()\n",
    "\n",
    "daily.hvplot(grid=True) * monthly.hvplot(grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a global image of SST on 10/1/2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sst_dy = sst.sel(time='2015-10-01').load()\n",
    "\n",
    "sst_dy.hvplot.quadmesh(x='lon', y='lat', \n",
    "                       geo=True, \n",
    "                       rasterize=True, \n",
    "                       cmap='rainbow', \n",
    "                       tiles='EsriImagery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check how the masked data looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "subset = sst_masked.sel(time='2015-10-01',lat=slice(-70,0)).load()\n",
    "\n",
    "subset.hvplot.quadmesh(x='lon', y='lat', \n",
    "                       geo=True, \n",
    "                       rasterize=True, \n",
    "                       cmap='rainbow', \n",
    "                       tiles='EsriImagery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the anomaly on 10/1/2015\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "anom_2015 = sst_anomaly.sel(time='2015-10-01',lat=slice(-60,70)).drop('dayofyear').load()\n",
    "\n",
    "anom_2015.hvplot.quadmesh(x='lon', y='lat', \n",
    "                          geo=True, \n",
    "                          rasterize=True, \n",
    "                          clim=(-2,2), \n",
    "                          cmap='seismic', \n",
    "                          tiles='EsriImagery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset the El Niño/La Niña Region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sst_elnino = sst.sel(lon=slice(-180,-70), lat=slice(-25,25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference the monthly mean temperature fields for Jan 2016 (El Niño) and Jan 2014 (normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sst_jan2016 = sst_elnino.sel(time=slice('2016-01-01','2016-02-01')).mean(dim='time')\n",
    "\n",
    "sst_jan2014 = sst_elnino.sel(time=slice('2014-01-01','2014-02-01')).mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sst_diff = (sst_jan2016 - sst_jan2014).load()\n",
    "\n",
    "sst_diff.hvplot.quadmesh(x='lon', y='lat', \n",
    "                         geo=True,                 \n",
    "                         rasterize=True, \n",
    "                         cmap='rainbow', \n",
    "                         tiles='EsriImagery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting on maps\n",
    "\n",
    "For plotting on maps, we rely on the excellent [cartopy](http://scitools.org.uk/cartopy/docs/latest/index.html) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In cartopy you need to define the map projection you want to plot.  \n",
    "\n",
    "- Common ones are Ortographic and PlateCarree.\n",
    "- You can add coastlines and gridlines to the axes as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_dy.hvplot.quadmesh(x='lon', y='lat', \n",
    "                       geo=True,         \n",
    "                       rasterize=True, \n",
    "                       cmap='rainbow', \n",
    "                       projection=ccrs.Orthographic(-80, 35),\n",
    "                       coastline='110m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please close cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A nice cartopy tutorial is [here](http://earthpy.org/tag/visualization.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xarray can do more!\n",
    "\n",
    "* concatentaion\n",
    "* open network located files with openDAP\n",
    "* import and export Pandas DataFrames\n",
    "* .nc dump to \n",
    "* groupby_bins\n",
    "* resampling and reduction\n",
    "\n",
    "For more details, read this blog post: http://continuum.io/blog/xray-dask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where can I find more info?\n",
    "\n",
    "### For more information about xarray\n",
    "\n",
    "- Read the [online documentation](http://xarray.pydata.org/)\n",
    "- Ask questions on [StackOverflow](http://stackoverflow.com/questions/tagged/python-xarray)\n",
    "- View the source code and file bug reports on [GitHub](http://github.com/pydata/xarray/)\n",
    "\n",
    "### For more doing data analysis with Python:\n",
    "\n",
    "- Thomas Wiecki, [A modern guide to getting started with Data Science and Python](http://twiecki.github.io/blog/2014/11/18/python-for-data-science/)\n",
    "- Wes McKinney, [Python for Data Analysis](http://shop.oreilly.com/product/0636920023784.do) (book)\n",
    "\n",
    "### Packages building on xarray for the geophysical sciences\n",
    "\n",
    "\n",
    "- [eofs](https://github.com/ajdawson/eofs): empirical orthogonal functions by Andrew Dawson\n",
    "- [infinite-diff](https://github.com/spencerahill/infinite-diff) by Spencer Hill \n",
    "- [aospy](https://github.com/spencerahill/aospy) by Spencer Hill and Spencer Clark\n",
    "- [regionmask](https://github.com/mathause/regionmask) by Mathias Hauser\n",
    "- [salem](https://github.com/fmaussion/salem) by Fabien Maussion\n",
    "\n",
    "Resources for teaching and learning xarray in geosciences:\n",
    "- [Fabien's teaching repo](https://github.com/fmaussion/teaching): courses that combine teaching climatology and xarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
